{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MTSI8gSzk71W"
   },
   "outputs": [],
   "source": [
    "# Meng-install library yang dibutuhkan untuk eksperimen\n",
    "# transformers  : library Hugging Face untuk model Transformer (BERT, IndoBERT, MiniLM, dll)\n",
    "# datasets      : library Hugging Face untuk pengelolaan dataset dan integrasi dengan Trainer\n",
    "# scikit-learn  : library machine learning untuk evaluasi (accuracy, precision, recall, F1, ROC-AUC, K-Fold)\n",
    "# torch         : PyTorch, framework deep learning yang digunakan untuk training model dan GPU acceleration\n",
    "# -q            : quiet mode, agar output instalasi tidak terlalu panjang\n",
    "\n",
    "!pip -q install transformers datasets scikit-learn torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Gpj6QTDglAIm"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "# Library bawaan Python untuk membaca dan menulis data berformat JSON\n",
    "# Digunakan untuk memuat dataset chatbot dari file .json\n",
    "\n",
    "import numpy as np\n",
    "# Library numerik untuk operasi array dan perhitungan matematis\n",
    "# Digunakan untuk softmax, mean, std, dan manipulasi array prediksi\n",
    "\n",
    "from pathlib import Path\n",
    "# Digunakan untuk menangani path file secara aman dan portable\n",
    "\n",
    "import os\n",
    "# Library bawaan Python untuk operasi sistem (cek folder, hapus file, dll.)\n",
    "# Digunakan saat menyimpan model terbaik dari cross-validation\n",
    "\n",
    "import torch\n",
    "# Framework deep learning PyTorch\n",
    "# Digunakan sebagai backend training model Transformer dan GPU acceleration\n",
    "\n",
    "import torch.nn.functional as F\n",
    "# Modul fungsi neural network PyTorch\n",
    "# Digunakan untuk softmax saat inferensi (prediksi confidence)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# Digunakan untuk melakukan Stratified K-Fold Cross-Validation\n",
    "# Stratified memastikan distribusi label di setiap fold tetap seimbang\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, label_binarize\n",
    "# LabelEncoder: mengubah label intent (string) menjadi angka\n",
    "# label_binarize: mengubah label menjadi format one-hot untuk ROC-AUC multi-class\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "# accuracy_score                  : menghitung akurasi klasifikasi\n",
    "# precision_recall_fscore_support : menghitung precision, recall, dan F1-score\n",
    "# roc_auc_score                   : menghitung ROC-AUC untuk klasifikasi multi-kelas\n",
    "# confusion_matrix                : menghasilkan confusion matrix\n",
    "\n",
    "from datasets import Dataset\n",
    "# Digunakan untuk membuat dataset Hugging Face\n",
    "# Memudahkan tokenisasi batch dan integrasi dengan Trainer\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    set_seed\n",
    ")\n",
    "# AutoTokenizer                    : memuat tokenizer sesuai model secara otomatis\n",
    "# AutoModelForSequenceClassification: model Transformer untuk klasifikasi intent\n",
    "# DataCollatorWithPadding          : melakukan padding dinamis per batch\n",
    "# TrainingArguments                : konfigurasi proses training\n",
    "# Trainer                          : API training tingkat tinggi dari Hugging Face\n",
    "# set_seed                         : mengatur seed agar eksperimen reproducible\n",
    "\n",
    "SEED = 42\n",
    "# Seed random untuk memastikan hasil eksperimen konsisten (reproducibility)\n",
    "\n",
    "K_FOLDS = 5\n",
    "# Jumlah fold untuk Stratified K-Fold Cross-Validation\n",
    "\n",
    "MODEL_NAME = \"microsoft/Multilingual-MiniLM-L12-H384\"\n",
    "# Nama model pretrained yang digunakan\n",
    "\n",
    "DATA_PATH = \"dataset_chatbot.json\"\n",
    "# Path menuju file dataset chatbot dalam format JSON\n",
    "\n",
    "BEST_DIR = \"./best_fold_model\"\n",
    "# Direktori untuk menyimpan model terbaik hasil cross-validation\n",
    "\n",
    "LR = 3e-5\n",
    "# Learning rate untuk optimizer AdamW\n",
    "# Nilai umum yang stabil untuk fine-tuning model Transformer\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "# Ukuran batch training\n",
    "# Disesuaikan agar muat di GPU dan tetap stabil\n",
    "\n",
    "EPOCHS = 30\n",
    "# Jumlah epoch training\n",
    "# Cukup besar untuk dataset kecil–menengah agar model konvergen\n",
    "\n",
    "MAX_LENGTH = 64\n",
    "# Panjang maksimum token input\n",
    "# Kalimat lebih panjang akan dipotong (truncation)\n",
    "\n",
    "set_seed(SEED)\n",
    "# Mengatur seed untuk PyTorch, NumPy, dan library terkait\n",
    "# Bertujuan agar hasil training dapat direproduksi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gfQE7CjglCUq",
    "outputId": "42e0d6da-d696-4b60-e9e8-165980a6df3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data: 2040\n",
      "Jumlah intent: 204\n",
      "Contoh: Bagaimana cara melihat data pribadi saya di sistem akademik Unpad? -> prosedur_akses_data_pribadi_mahasiswa\n",
      "num_labels: 204\n"
     ]
    }
   ],
   "source": [
    "# Membaca isi file dataset (JSON) dari path DATA_PATH\n",
    "# File dibaca sebagai teks (string) dengan encoding UTF-8\n",
    "# json.loads digunakan untuk mengubah string JSON menjadi objek Python (list/dict)\n",
    "raw = json.loads(Path(DATA_PATH).read_text(encoding=\"utf-8\"))\n",
    "\n",
    "# Menyiapkan dua list kosong:\n",
    "# - texts   : untuk menyimpan pertanyaan (input model)\n",
    "# - intents : untuk menyimpan label intent (kelas)\n",
    "texts, intents = [], []\n",
    "\n",
    "# Melakukan iterasi untuk setiap data (baris) dalam dataset\n",
    "for row in raw:\n",
    "    # Mengambil field \"question\" dari JSON\n",
    "    # strip() menghapus spasi di awal dan akhir teks\n",
    "    q = (row.get(\"question\") or \"\").strip()\n",
    "\n",
    "    # Mengambil field \"intent\" dari JSON\n",
    "    it = (row.get(\"intent\") or \"\").strip()\n",
    "    # hanya data yang memiliki question DAN intent yang dimasukkan\n",
    "    if q and it:\n",
    "        texts.append(q)       # simpan pertanyaan ke list texts\n",
    "        intents.append(it)    # simpan intent ke list intents\n",
    "\n",
    "# Menampilkan jumlah total data valid yang digunakan\n",
    "print(\"Total data:\", len(texts))\n",
    "\n",
    "# Menampilkan jumlah intent unik dalam dataset\n",
    "# set(intents) digunakan untuk menghilangkan duplikasi label\n",
    "print(\"Jumlah intent:\", len(set(intents)))\n",
    "\n",
    "# Menampilkan satu contoh pasangan (question -> intent)\n",
    "# Berguna untuk sanity check apakah data sudah benar\n",
    "print(\"Contoh:\", texts[0], \"->\", intents[0])\n",
    "\n",
    "# Membuat objek LabelEncoder dari scikit-learn\n",
    "# Digunakan untuk mengubah label intent (string) menjadi angka\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Mengubah semua intent (string) menjadi label numerik (0, 1, 2, ...)\n",
    "y = le.fit_transform(intents)\n",
    "\n",
    "# Menghitung jumlah total kelas / intent\n",
    "# le.classes_ berisi daftar intent unik yang telah di-encode\n",
    "num_labels = len(le.classes_)\n",
    "\n",
    "# Menampilkan jumlah kelas (akan digunakan saat inisialisasi model)\n",
    "print(\"num_labels:\", num_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274,
     "referenced_widgets": [
      "a6c458f4bb554027abd9590f3324b439",
      "46afd9e8b32c4812a70a0345091ef103",
      "839d7ba746b0496ba021b1067135cc75",
      "ae2784bc6bec4039b85f8803e3fa9f99",
      "3fd81e3f0372497f90f165b944eeea72",
      "f79366eb30264f5bafeb6190f87a24c2",
      "b53b856a007a46fda60707d450a8e06b",
      "4f15aa02e1e145a1ab981fcfcc7345fa",
      "788269aabaf5474ab1ad52c147d2398c",
      "6273d0915e0f43c0950dfeb28db4c030",
      "d38bc7221bce4040b7b49f05b5d80a39",
      "56736f0a40734df89adb08c0d76fa880",
      "3c2e8fbbbde645ce87c250a7256aea7c",
      "7b11b8cc30fb4f0e94e73b80b57254ca",
      "bce4c1af327f4fa8a16748a07e391eda",
      "ac94a47724a540869dce734537728051",
      "f1795917f33c42199e565569281204b8",
      "6b3cffcbf6a14badbe4e7c975c69f441",
      "13f4f08044994d73b13987fe9f822aa0",
      "dc4cff2fa51c4b77bcbed8f934728490",
      "3578b440e85b431ba4f7ae6668a07258",
      "40c002ecd040445da8c9b21e458215f7",
      "11d391cd097744699c5a051e7fec147d",
      "34237f1f7199441584cfa4ec9da61b72",
      "7cc30ab012fa405d819f0356c8a3aa6d",
      "af3082574b664885bbccdb6e625ce0c7",
      "1e187e9f74244c07903bdcef2e911cff",
      "fa2dabe008504ac7b72b265fa5597c89",
      "fe1d76cb84d847e8b3b5c56fc9a48fd3",
      "9f9600b9acfb44bf8d657f157625ab08",
      "1bb8bfd12cb04f0883af9d35860f7855",
      "20bf9a9e25504d26aed89c2e822cf4fc",
      "865ea8123e2845fb89e2b62b56bab731",
      "9b3d6bcaa5d7459a90433aff64a883b6",
      "79fed42431904f8ebd007fa9278524d7",
      "23a09e8771014ee1987d2c314b851007",
      "1171096abe124158818954de7b405d17",
      "a69dae51a28c4e489d99a51c1a7d72e5",
      "4070844b173347bc8d65e918a0bad9ec",
      "7d36ed15a9c94717b3eb86784454c85f",
      "44a3381d346a4f098208bb755cc4da48",
      "18a5c196862740e499a89b265dd4f1c3",
      "49e9406bbf7d4131a9ea62d9806f78f1",
      "13271fb8235f473e8630a3c4cdac4d6c"
     ]
    },
    "id": "ojAf1tdxukVR",
    "outputId": "c2b4b789-4014-49f4-e0a4-a567ee20e30b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Memuat tokenizer sesuai dengan model pretrained yang digunakan\n",
    "# AutoTokenizer akan otomatis memilih jenis tokenizer yang tepat\n",
    "# berdasarkan MODEL_NAME (misalnya BERT, ALBERT, MiniLM, dll.)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# DataCollatorWithPadding digunakan untuk melakukan padding secara dinamis\n",
    "# Padding dilakukan berdasarkan panjang teks terpanjang di setiap batch\n",
    "# Hal ini membuat training lebih efisien dibanding padding ke panjang maksimum\n",
    "collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "def tokenize_fn(batch):\n",
    "    \"\"\"\n",
    "    Fungsi untuk mengubah teks mentah menjadi token numerik\n",
    "    yang dapat diproses oleh model Transformer.\n",
    "\n",
    "    Parameter:\n",
    "    - batch[\"text\"]: kumpulan teks (pertanyaan) dalam satu batch\n",
    "\n",
    "    Proses:\n",
    "    - truncation=True  : memotong teks jika melebihi MAX_LENGTH\n",
    "    - max_length       : batas maksimum jumlah token\n",
    "    \"\"\"\n",
    "    return tokenizer(\n",
    "        batch[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=MAX_LENGTH\n",
    "    )\n",
    "\n",
    "def softmax_np(logits):\n",
    "    \"\"\"\n",
    "    Menghitung softmax menggunakan NumPy.\n",
    "\n",
    "    Digunakan untuk mengubah nilai logit (skor mentah model)\n",
    "    menjadi probabilitas kelas.\n",
    "\n",
    "    logits: array dengan shape [n_samples, n_classes]\n",
    "    \"\"\"\n",
    "    # Mengurangi nilai maksimum tiap baris untuk stabilitas numerik\n",
    "    logits = logits - np.max(logits, axis=1, keepdims=True)\n",
    "\n",
    "    # Menghitung eksponensial dari setiap nilai logit\n",
    "    exp = np.exp(logits)\n",
    "\n",
    "    # Membagi dengan total eksponensial untuk mendapatkan probabilitas\n",
    "    return exp / np.sum(exp, axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "def compute_all_metrics(y_true, y_pred, y_proba, num_labels):\n",
    "    \"\"\"\n",
    "    Menghitung berbagai metrik evaluasi untuk klasifikasi multi-kelas.\n",
    "\n",
    "    Parameter:\n",
    "    - y_true     : label asli (ground truth)\n",
    "    - y_pred     : label hasil prediksi model\n",
    "    - y_proba    : probabilitas hasil softmax\n",
    "    - num_labels : jumlah total kelas / intent\n",
    "    \"\"\"\n",
    "\n",
    "    # Menghitung akurasi klasifikasi\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # Menghitung precision, recall, dan F1-score\n",
    "    # average=\"macro\" digunakan agar semua kelas diperlakukan setara\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        average=\"macro\",\n",
    "        zero_division=0\n",
    "    )\n",
    "\n",
    "    # Mengubah label asli menjadi representasi one-hot\n",
    "    # Diperlukan untuk perhitungan ROC-AUC multi-kelas\n",
    "    y_true_oh = label_binarize(\n",
    "        y_true,\n",
    "        classes=list(range(num_labels))\n",
    "    )\n",
    "\n",
    "    # Menghitung ROC-AUC dengan pendekatan One-vs-Rest (OvR)\n",
    "    # Try-except digunakan karena ROC-AUC bisa gagal jika\n",
    "    # suatu fold tidak mengandung semua kelas\n",
    "    try:\n",
    "        auc = roc_auc_score(\n",
    "            y_true_oh,\n",
    "            y_proba,\n",
    "            multi_class=\"ovr\",\n",
    "            average=\"macro\"\n",
    "        )\n",
    "    except ValueError:\n",
    "        auc = float(\"nan\")\n",
    "\n",
    "    # Menghitung confusion matrix\n",
    "    # Baris = label sebenarnya, kolom = label prediksi\n",
    "    cm = confusion_matrix(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        labels=list(range(num_labels))\n",
    "    )\n",
    "\n",
    "    # Mengembalikan seluruh metrik dalam bentuk dictionary\n",
    "    return {\n",
    "        \"accuracy\": float(acc),\n",
    "        \"precision_macro\": float(prec),\n",
    "        \"recall_macro\": float(rec),\n",
    "        \"f1_macro\": float(f1),\n",
    "        \"roc_auc_ovr_macro\": float(auc),\n",
    "        \"confusion_matrix\": cm,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "964be54a87384070b0c03261158e4017",
      "441b6f12f90e496fac498ec67694cf3a",
      "97f9b73c1c2c4428a9fc27a2b728d481",
      "daedc8762edd47ea92f9d74067543cb9",
      "1ca20502799143499e9dc60d55831a19",
      "a30752ea5c56447b9056028622315e06",
      "97bf429eaa1642138c1859c9e0145f5d",
      "1ec6d5fa495d4412a0b065698a0d8929",
      "4682b285ec534de7a78b2e47941ce52f",
      "8ea6651c2944429789c2d52085ba1257",
      "ee86668ec2304887a2f54d01d22d7e3d",
      "7e3b908cf8164f71a3d652462dad1cca",
      "701e6007001f448cb50d731f149c0a7c",
      "96aa6f9354784fdeae41e0375efc3305",
      "e7f8c4014fab4737ab34c211ddde5810",
      "895ce340f2574ba4a6e4ba02ae03bdbd",
      "1bc5dc12c15540e5a03d95e9a50219fe",
      "c0bb3564648d4677bd2067f619ee6352",
      "6383b3d41b114d1f9c33a30eb01f72de",
      "bd45557ab1dd4f26b8cc005d9d8b45c1",
      "68cadfff49d44d28a814ed1d24d46b1d",
      "13535834ab2644dba1bf02ac107dbbea",
      "3a0caf3b33374ee1bf2aa0ad4abe1eda",
      "de300f3e17824c5f9d7fa0403605c272",
      "41abdb576a334ffb800bcccb330d0440",
      "c381ac58b2064aacb3460a85205ebb5f",
      "0e3567ce6aee4d59a72475a2295f1b4e",
      "cb1fcc2c225f488cbb842fe1126abc99",
      "8549d65fdd3c455cbcdbdce5c3a87648",
      "7765c58f79324aaa970153bdf278a795",
      "58d111da4dfb4fe88196f09e03ef3e4a",
      "7a4f073dd4f84497bf7178e462e195c9",
      "3e84429fbb834ec5b13b8d4ade4c2769",
      "e1a68436d8c349f8aacda9d7644a26a9",
      "8d6dd5c00dc64abebbd32acf1521ef85",
      "188259871eac4fbe8e6079e1ca1aa2df",
      "07e7d43dbe14413caf16f58c6d098607",
      "19a87264452d4930b1c90611f4f1a874",
      "48418ba22fae4204811b2d056b4daef8",
      "b18a6143d2a6490eb0f0f903f97205fc",
      "9348997b487348cabc84c3af103387a3",
      "458e13bbafc54752b7792e56dc7f21ab",
      "d0176837b882469fb1b945990e5fcf57",
      "e9275d4c420044dfaffb6a243c84f692",
      "60314df5951240948efbb1fe265554b7",
      "e01e1732bd164db59d895196a5375a09",
      "eace6cee6cfb4805bfe098b69c1e5747",
      "bff44275baae4c85a1d7ee0f06f1e134",
      "53d5c212a8754c3bab85cdfbe873e021",
      "fc4865e59ad141cab6bc957a0cd521d2",
      "5a48beec623b4dd1a8da4eca2d84293f",
      "2157923d65174c56af0a2d9fd67d7e7c",
      "8da8da4473ad48eeb7e15f68b1690a5c",
      "83eb88cf677f4a5f8d383a43c58c4292",
      "b389dac7c3db418eb3e3d90d33b5dbf4",
      "e8c20610d0444e3484442ce6f2e09958",
      "30e74f5c6b094d489ba47b30534b46c1",
      "0afe733e92bf4a6b8c3588cb5e49ab29",
      "719d191b60984a2da7f7aa9561010dfa",
      "e9bea45b878e481482810924820f189c",
      "d69ed43cc4274b058346d032982be831",
      "e67dd6bd8e3740ac8a136e1f3b0e11ad",
      "6c615935c298482b854ac8683c41af09",
      "7bb9acfb4f254ea8b279c40a6799dc67",
      "f436d5cf1be94e2eb0eb1d7041199c35",
      "75c5b9a77523494c95ad36528ee5bddc",
      "15e326c8078043cbb3c7b81718a89044",
      "816fa3bad110499fa1ef2c8b62085ba2",
      "f535456ba6cf4a308fd6496f543b62ae",
      "a784e4059d0f45709266c9a9ef41a8e0",
      "c1b6f07d2d134154bed2bca3b084837f",
      "62c5f1d1f957438f97154c9230a039da",
      "eb95caeb8a4442c6997843f174ce0bf1",
      "5abe3151304645128a795b23c66e198a",
      "7747c2be0e2143c69ca1868bbb3e38ba",
      "61b56cd35fa742c28476391f69bbebdc",
      "3c6c965e07a64a869c78ea47e8df0436",
      "30ce260c8c694ceb8aacbb81baf86525",
      "225b39b8933c40c0b5dcbe0c943dd5b2",
      "3310e4502a694a12a59c66da608cfb86",
      "cfd0e7f919374968bfbfa95d9af721c4",
      "aec3cb40e16c463a8468338d4310d22d",
      "f6763c1428c44e76a2b8165f5597c04b",
      "1be1d0d0bffd49cfbe0d27cae898a908",
      "bd9517f860ac4271944660b1ef287e36",
      "57beeb4feb8649ac9b6a534624ae69ec",
      "d067be805d0b476dbca9a42fe5829cf4",
      "4257c5d37a5b4ce6a713e8146f6fa6e9",
      "995fa99fe4ab4dce8f3d4c0bca0a342e",
      "c3d1452c16f745d29cd246f3f626c020",
      "2d634fcf01e549c7b41edd4748cc19bd",
      "d7ae08e0b2b74dffb7f23bdd84ba5b34",
      "353198c3a0cb49eeb165b0f5e5069c9e",
      "876d17e6530c41c599407d9ea220e42e",
      "e5dc094184a24be39f1ed37398173525",
      "91a202d40e4647ef96c86a0d57e02adc",
      "93ac9c36e5014529be6c0fcb484442c9",
      "fe032fb7161042e6afba3893f8352119",
      "c23c56d41c71400f9c9504b5079977cd",
      "fbb06986754a43418749eee4e8b1be7b",
      "5eb64a31581e4ab9ab4c414df3c6fae3",
      "fcde8e2ae7c640bd91b278be977324cf",
      "53d60cc80a5c4432ad7b4180414ae29f",
      "ba1ed1cecce54869a0268f7112c2b8dc",
      "66d7f489809b4efdbd7f5438444a84bb",
      "90b984257e844f1cb64541d2e0a85814",
      "72b17f93f8124c958d5a20f2acb9bd1a",
      "f486ba85cd724642bd187c457e59bbf9",
      "6a37b87770314a35a9aff45d2ac92b18",
      "03d6fb6f2152419f8a28ad823edfec49",
      "e37bd68c0d1c40288966e47c06cc03bf",
      "d515366381ec41ac82fca2bb05208b83",
      "92528bfe27ea4ba68170d53f303ff111",
      "398566f2205846d98c8da7ce69bf7586",
      "12882eb69cac43309bfa111f0a92fbb1",
      "b11869c69d4b44ceaf16f0db8d702a1a",
      "a4a770f562d04cb9bed27327aaddeb9e",
      "c9408a9622034c37ac436cacda14586b",
      "a1e37ba07c9142d9b1d0ab7edb465c24",
      "5af6b6a6d3f24b0eaa69a27a9153e955",
      "38d1514591c94ffa829004825a1a9111",
      "b95ffc1553ac45debe26275460a54f67",
      "c46451906f8a47b18d8b18a83974a844",
      "8647d6dc3cee4bb5874e860405d1fab4",
      "2e8bd2b40e2e4c6d994a961057eaecd4",
      "0dbb3fd8ddfb42239827e4993d5cfb62",
      "0870f07a906f4bd7a4753aa9888fddf9",
      "c5672c290a5a4d5c803eecb2a2c45f38",
      "921cb4ddb4ac406e86fe42f77d6493b0",
      "614780c7cd054b5aaf4876dcab2d7fa7",
      "8f915017492041e79066fca31379597a",
      "4b4bcbe70fa742c5bf75f1f5070bfb34"
     ]
    },
    "id": "R3iwathUsk_e",
    "outputId": "7c83bb3e-909b-4466-81ff-0d153257a259"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== FOLD 1/5 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/Multilingual-MiniLM-L12-H384 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-3330309801.py:79: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 0, 'pad_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3060' max='3060' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3060/3060 13:15, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>5.321400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>5.321500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>5.298300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>5.252000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>5.186900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>5.131500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>5.068200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>5.013200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>4.955300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.905800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>4.850900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>4.802600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>4.747100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>4.711300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>4.668300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>4.618500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>4.581700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>4.531200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>4.500300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>4.468800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>4.422500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>4.396300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>4.354600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>4.323400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>4.288800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>4.259500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>4.248900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>4.210700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>4.174500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>4.156900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>4.135300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>4.103800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>4.084400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>4.064400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>4.032200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>4.011300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>3.993900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>3.972400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>3.962200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.931300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>3.922300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>3.901400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>3.884300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>3.864800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>3.859200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>3.842100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>3.831700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>3.813400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>3.803000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>3.786900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>3.788700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>3.764100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>3.775700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>3.750400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>3.761900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>3.738100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>3.748400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>3.744600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>3.728400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>3.735200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>3.731200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold metrics: {'accuracy': 0.5563725490196079, 'precision_macro': 0.49525881653909337, 'recall_macro': 0.5563725490196079, 'f1_macro': 0.4842474146653713, 'roc_auc_ovr_macro': 0.9899425287356322, 'fold': 1}\n",
      "✅ Best model updated: fold=1, best_f1=0.4842 -> saved to ./best_fold_model\n",
      "\n",
      "==================== FOLD 2/5 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/Multilingual-MiniLM-L12-H384 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-3330309801.py:79: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 0, 'pad_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3060' max='3060' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3060/3060 10:27, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>5.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>5.323200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>5.303500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>5.265500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>5.192600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>5.136700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>5.062400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>5.010800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>4.946600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.897300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>4.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>4.785500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>4.734600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>4.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>4.628300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>4.595500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>4.543800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>4.506100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>4.452000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>4.408000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>4.366200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>4.337100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>4.295600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>4.259600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>4.220900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>4.182300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>4.151600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>4.130600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>4.089000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>4.057900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>4.033400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>3.997200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>3.981400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>3.951100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>3.921500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>3.894800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>3.885300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>3.864700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>3.832300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.809200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>3.802900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>3.776300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>3.765100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>3.741100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>3.725400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>3.716800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>3.703300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>3.681900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>3.686100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>3.660800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>3.660100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>3.640500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>3.639000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>3.627200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>3.627100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>3.615600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>3.614300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>3.612900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>3.600300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>3.605800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>3.599300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold metrics: {'accuracy': 0.5514705882352942, 'precision_macro': 0.5265559331735803, 'recall_macro': 0.5514705882352942, 'f1_macro': 0.49730449289272816, 'roc_auc_ovr_macro': 0.9942287259731478, 'fold': 2}\n",
      "✅ Best model updated: fold=2, best_f1=0.4973 -> saved to ./best_fold_model\n",
      "\n",
      "==================== FOLD 3/5 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/Multilingual-MiniLM-L12-H384 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-3330309801.py:79: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 0, 'pad_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3060' max='3060' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3060/3060 12:49, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>5.320500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>5.322700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>5.302500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>5.260800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>5.188200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>5.130400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>5.065600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>5.011800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>4.946200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.900700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>4.841000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>4.796100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>4.739600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>4.699100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>4.647200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>4.605600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>4.558400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>4.515400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>4.473200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>4.423000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>4.381700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>4.352500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>4.307400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>4.269400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>4.233900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>4.195700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>4.165800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>4.143300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>4.096900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>4.063400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>4.047800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>4.012700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>3.970100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>3.955700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>3.928300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>3.905200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>3.887900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>3.854200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>3.830700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.806600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>3.789600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>3.763800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>3.763100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>3.737500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>3.719100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>3.715900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>3.692400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>3.673700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>3.674200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>3.648800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>3.643700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>3.627600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>3.624400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>3.617800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>3.608200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>3.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>3.607200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>3.598000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>3.586900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>3.585900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>3.588900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold metrics: {'accuracy': 0.5514705882352942, 'precision_macro': 0.5020347027699968, 'recall_macro': 0.5514705882352942, 'f1_macro': 0.48965990436578666, 'roc_auc_ovr_macro': 0.9807422969187675, 'fold': 3}\n",
      "\n",
      "==================== FOLD 4/5 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/Multilingual-MiniLM-L12-H384 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-3330309801.py:79: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 0, 'pad_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3060' max='3060' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3060/3060 11:58, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>5.320500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>5.322500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>5.304900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>5.264800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>5.190400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>5.126500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>5.053900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>5.000300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>4.931900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.883200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>4.826400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>4.768800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>4.715000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>4.669400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>4.604900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>4.574000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>4.516300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>4.478700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>4.430400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>4.378900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>4.339000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>4.308600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>4.265000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>4.219800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>4.181100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>4.145300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>4.117600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>4.096600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>4.050400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>4.011600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>3.993100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>3.955100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>3.926100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>3.906900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>3.876200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>3.854200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>3.835500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>3.806700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>3.774400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.753200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>3.740700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>3.716400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>3.710900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>3.684500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>3.669700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>3.650100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>3.636000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>3.615000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>3.621600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>3.599100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>3.594300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>3.569500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>3.575700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>3.566400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>3.555500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>3.548000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>3.548300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>3.547000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>3.529400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>3.534100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>3.537300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold metrics: {'accuracy': 0.6299019607843137, 'precision_macro': 0.5751750700280113, 'recall_macro': 0.6299019607843137, 'f1_macro': 0.5653906006847182, 'roc_auc_ovr_macro': 0.9941562832029363, 'fold': 4}\n",
      "✅ Best model updated: fold=4, best_f1=0.5654 -> saved to ./best_fold_model\n",
      "\n",
      "==================== FOLD 5/5 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/Multilingual-MiniLM-L12-H384 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipython-input-3330309801.py:79: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': 2, 'bos_token_id': 0, 'pad_token_id': 1}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3060' max='3060' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3060/3060 12:56, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>5.320300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>5.323500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>5.306400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>5.269100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>5.194700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>5.135100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>5.063400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>5.008300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>4.936500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.895900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>4.837000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>4.777700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>4.727900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>4.678800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>4.625100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>4.583900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>4.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>4.488800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>4.441900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>4.399900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>4.349100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>4.324500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>4.276600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>4.235800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>4.196800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>4.166000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>4.125300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>4.102200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>4.061800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>4.027700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>3.997600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>3.965000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>3.936100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>3.912800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>3.882500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>3.854000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>3.841900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>3.816600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>3.779000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.752900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>3.746900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>3.716700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>3.705900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>3.680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>3.658600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>3.648400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>3.626200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>3.610700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>3.616300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>3.589200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>3.587300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>3.570100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>3.571200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>3.560500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>3.544700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>3.544800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>3.539900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>3.536400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>3.521700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>3.532500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>3.516400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold metrics: {'accuracy': 0.5833333333333334, 'precision_macro': 0.5081915089268031, 'recall_macro': 0.5833333333333334, 'f1_macro': 0.5079451050039285, 'roc_auc_ovr_macro': 0.9921822177146721, 'fold': 5}\n",
      "\n",
      "==================== BEST FOLD ====================\n",
      "Best fold: 4\n",
      "Best metrics: {'accuracy': 0.6299019607843137, 'precision_macro': 0.5751750700280113, 'recall_macro': 0.6299019607843137, 'f1_macro': 0.5653906006847182, 'roc_auc_ovr_macro': 0.9941562832029363, 'fold': 4}\n"
     ]
    }
   ],
   "source": [
    "# Membuat objek StratifiedKFold\n",
    "# n_splits=K_FOLDS   : jumlah fold (misalnya 5-fold)\n",
    "# shuffle=True       : data diacak sebelum dibagi\n",
    "# random_state=SEED  : agar pembagian data konsisten (reproducible)\n",
    "skf = StratifiedKFold(n_splits=K_FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "# List untuk menyimpan hasil evaluasi tiap fold (accuracy, precision, recall, f1, dll)\n",
    "fold_results = []\n",
    "\n",
    "# List untuk menyimpan confusion matrix dari tiap fold\n",
    "conf_mats = []\n",
    "\n",
    "# Variabel untuk menyimpan informasi fold terbaik\n",
    "best_fold = None            # nomor fold terbaik\n",
    "best_score = -1.0           # skor terbaik (pakai F1-macro)\n",
    "best_metrics = None         # metrik dari fold terbaik\n",
    "\n",
    "# Mengecek apakah folder BEST_DIR sudah ada\n",
    "if os.path.isdir(BEST_DIR):\n",
    "    # Menghapus seluruh isi folder BEST_DIR\n",
    "    # Ini dilakukan agar model lama tidak tertimpa atau tercampur\n",
    "    for root, dirs, files in os.walk(BEST_DIR, topdown=False):\n",
    "        for name in files:\n",
    "            os.remove(os.path.join(root, name))  # hapus file\n",
    "        for name in dirs:\n",
    "            os.rmdir(os.path.join(root, name))   # hapus subfolder\n",
    "    os.rmdir(BEST_DIR)  # hapus folder utama\n",
    "\n",
    "# Looping untuk setiap fold\n",
    "# skf.split(texts, y) akan menghasilkan index data train dan validation\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(texts, y), start=1):\n",
    "\n",
    "    print(f\"\\n==================== FOLD {fold}/{K_FOLDS} ====================\")\n",
    "\n",
    "    # Menyusun data training berdasarkan index train_idx\n",
    "    train_data = {\n",
    "        \"text\":  [texts[i] for i in train_idx],  # pertanyaan untuk training\n",
    "        \"label\": [int(y[i]) for i in train_idx]  # label intent untuk training\n",
    "    }\n",
    "\n",
    "    # Menyusun data validasi berdasarkan index val_idx\n",
    "    val_data = {\n",
    "        \"text\":  [texts[i] for i in val_idx],     # pertanyaan untuk validasi\n",
    "        \"label\": [int(y[i]) for i in val_idx]     # label intent untuk validasi\n",
    "    }\n",
    "\n",
    "    # Mengubah dictionary menjadi Hugging Face Dataset\n",
    "    # lalu melakukan tokenisasi secara batch\n",
    "    ds_train = Dataset.from_dict(train_data).map(tokenize_fn, batched=True)\n",
    "    ds_val   = Dataset.from_dict(val_data).map(tokenize_fn, batched=True)\n",
    "\n",
    "    # Menghapus kolom \"text\" karena model hanya butuh input_ids & attention_mask\n",
    "    # with_format(\"torch\") agar output berupa tensor PyTorch\n",
    "    ds_train = ds_train.remove_columns([\"text\"]).with_format(\"torch\")\n",
    "    ds_val   = ds_val.remove_columns([\"text\"]).with_format(\"torch\")\n",
    "\n",
    "    # Model selalu dibuat ulang di setiap fold\n",
    "    # Ini penting agar tidak terjadi kebocoran informasi antar fold\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        num_labels=num_labels\n",
    "    )\n",
    "\n",
    "    # Konfigurasi training\n",
    "    args = TrainingArguments(\n",
    "        output_dir=f\"./cv_runs/fold_{fold}\",   # folder output khusus fold ini\n",
    "        learning_rate=LR,                      # learning rate\n",
    "        per_device_train_batch_size=BATCH_SIZE,\n",
    "        per_device_eval_batch_size=BATCH_SIZE,\n",
    "        num_train_epochs=EPOCHS,               # jumlah epoch\n",
    "        weight_decay=0.01,                     # regularisasi\n",
    "        logging_steps=50,                      # interval logging\n",
    "        report_to=\"none\",                      # tidak pakai wandb/tensorboard\n",
    "        seed=SEED,\n",
    "        fp16=torch.cuda.is_available(),        # pakai FP16 jika ada GPU\n",
    "    )\n",
    "\n",
    "    # Membuat Trainer (API training Hugging Face)\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=ds_train,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=collator,\n",
    "    )\n",
    "\n",
    "    # TRAINING MODEL PADA FOLD INI\n",
    "    trainer.train()\n",
    "\n",
    "    # Melakukan prediksi pada data validasi\n",
    "    out = trainer.predict(ds_val)\n",
    "\n",
    "    # Logits = skor mentah model (belum softmax)\n",
    "    logits = out.predictions\n",
    "\n",
    "    # Label asli (ground truth)\n",
    "    y_true = out.label_ids.astype(int)\n",
    "\n",
    "    # Mengubah logits menjadi probabilitas\n",
    "    y_proba = softmax_np(logits)\n",
    "\n",
    "    # Mengambil kelas dengan probabilitas tertinggi\n",
    "    y_pred = np.argmax(y_proba, axis=1)\n",
    "\n",
    "    # Menghitung seluruh metrik evaluasi\n",
    "    metrics = compute_all_metrics(y_true, y_pred, y_proba, num_labels)\n",
    "\n",
    "    # Mengambil confusion matrix\n",
    "    cm = metrics[\"confusion_matrix\"]\n",
    "\n",
    "    # Menyimpan metrik (tanpa confusion matrix agar ringkas)\n",
    "    fold_row = {k: v for k, v in metrics.items() if k != \"confusion_matrix\"}\n",
    "    fold_row[\"fold\"] = fold\n",
    "\n",
    "    fold_results.append(fold_row)\n",
    "    conf_mats.append(cm)\n",
    "\n",
    "    print(\"Fold metrics:\", fold_row)\n",
    "\n",
    "    # ======================\n",
    "    # MENENTUKAN FOLD TERBAIK\n",
    "    # ======================\n",
    "\n",
    "    # Jika F1-macro fold ini lebih baik dari sebelumnya\n",
    "    if fold_row[\"f1_macro\"] > best_score:\n",
    "        best_score = fold_row[\"f1_macro\"]\n",
    "        best_fold = fold\n",
    "        best_metrics = fold_row\n",
    "\n",
    "        # Membuat folder untuk menyimpan model terbaik\n",
    "        os.makedirs(BEST_DIR, exist_ok=True)\n",
    "\n",
    "        # Menyimpan model dan tokenizer dari fold terbaik\n",
    "        trainer.save_model(BEST_DIR)\n",
    "        tokenizer.save_pretrained(BEST_DIR)\n",
    "\n",
    "        # Menyimpan mapping label index -> intent\n",
    "        with open(os.path.join(BEST_DIR, \"label_names.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(le.classes_.tolist(), f, ensure_ascii=False, indent=2)\n",
    "        print(\n",
    "            f\"✅ Best model updated: \"\n",
    "            f\"fold={best_fold}, best_f1={best_score:.4f} -> saved to {BEST_DIR}\"\n",
    "        )\n",
    "\n",
    "# ======================\n",
    "# RINGKASAN FOLD TERBAIK\n",
    "# ======================\n",
    "\n",
    "print(\"\\n==================== BEST FOLD ====================\")\n",
    "print(\"Best fold:\", best_fold)\n",
    "print(\"Best metrics:\", best_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fk-_nHsXsn_U",
    "outputId": "9698a9ed-fc70-42a3-92f8-88962354e463"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== CV SUMMARY (K=5) ====================\n",
      "Accuracy           : 0.5745 ± 0.0301\n",
      "Precision (macro)  : 0.5214 ± 0.0288\n",
      "Recall (macro)     : 0.5745 ± 0.0301\n",
      "F1-score (macro)   : 0.5089 ± 0.0293\n",
      "ROC-AUC (OvR macro): 0.9903 ± 0.0050\n",
      "\n",
      "Confusion matrix rata-rata shape: (204, 204)\n",
      "\n",
      "Detail per fold:\n",
      "{'accuracy': 0.5563725490196079, 'precision_macro': 0.49525881653909337, 'recall_macro': 0.5563725490196079, 'f1_macro': 0.4842474146653713, 'roc_auc_ovr_macro': 0.9899425287356322, 'fold': 1}\n",
      "{'accuracy': 0.5514705882352942, 'precision_macro': 0.5265559331735803, 'recall_macro': 0.5514705882352942, 'f1_macro': 0.49730449289272816, 'roc_auc_ovr_macro': 0.9942287259731478, 'fold': 2}\n",
      "{'accuracy': 0.5514705882352942, 'precision_macro': 0.5020347027699968, 'recall_macro': 0.5514705882352942, 'f1_macro': 0.48965990436578666, 'roc_auc_ovr_macro': 0.9807422969187675, 'fold': 3}\n",
      "{'accuracy': 0.6299019607843137, 'precision_macro': 0.5751750700280113, 'recall_macro': 0.6299019607843137, 'f1_macro': 0.5653906006847182, 'roc_auc_ovr_macro': 0.9941562832029363, 'fold': 4}\n",
      "{'accuracy': 0.5833333333333334, 'precision_macro': 0.5081915089268031, 'recall_macro': 0.5833333333333334, 'f1_macro': 0.5079451050039285, 'roc_auc_ovr_macro': 0.9921822177146721, 'fold': 5}\n"
     ]
    }
   ],
   "source": [
    "# Fungsi untuk menghitung rata-rata dan standar deviasi\n",
    "# np.nanmean / np.nanstd dipakai agar nilai NaN (misalnya dari ROC-AUC)\n",
    "# tidak menyebabkan error pada perhitungan\n",
    "def mean_std(xs):\n",
    "    return float(np.nanmean(xs)), float(np.nanstd(xs))\n",
    "\n",
    "# Mengambil nilai accuracy, precision, recall, dll dari setiap fold\n",
    "accs  = [r[\"accuracy\"] for r in fold_results]\n",
    "precs = [r[\"precision_macro\"] for r in fold_results]\n",
    "recs  = [r[\"recall_macro\"] for r in fold_results]\n",
    "f1s   = [r[\"f1_macro\"] for r in fold_results]\n",
    "aucs  = [r[\"roc_auc_ovr_macro\"] for r in fold_results]\n",
    "\n",
    "# Menampilkan rata-rata ± standar deviasi untuk setiap metrik\n",
    "print(\"\\n==================== CV SUMMARY (K=5) ====================\")\n",
    "m, s = mean_std(accs);  print(f\"Accuracy           : {m:.4f} ± {s:.4f}\")\n",
    "m, s = mean_std(precs); print(f\"Precision (macro)  : {m:.4f} ± {s:.4f}\")\n",
    "m, s = mean_std(recs);  print(f\"Recall (macro)     : {m:.4f} ± {s:.4f}\")\n",
    "m, s = mean_std(f1s);   print(f\"F1-score (macro)   : {m:.4f} ± {s:.4f}\")\n",
    "m, s = mean_std(aucs);  print(f\"ROC-AUC (OvR macro): {m:.4f} ± {s:.4f}\")\n",
    "\n",
    "# Menghitung confusion matrix rata-rata dari seluruh fold\n",
    "cm_avg = np.mean(np.stack(conf_mats), axis=0)\n",
    "print(\"\\nConfusion matrix rata-rata shape:\", cm_avg.shape)\n",
    "\n",
    "# Menampilkan detail hasil evaluasi untuk setiap fold\n",
    "print(\"\\nDetail per fold:\")\n",
    "for r in fold_results:\n",
    "    print(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 807
    },
    "id": "-BnTr1mesutO",
    "outputId": "e4a73e57-f2ad-4a4f-bc95-f13ad6f49dd2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Import library matplotlib untuk visualisasi data (plot / grafik)\n",
    "\n",
    "# Membuat figure (kanvas) dengan ukuran 10 x 8 inci\n",
    "# Ukuran ini dipilih agar confusion matrix terlihat jelas\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Menampilkan confusion matrix rata-rata sebagai gambar (heatmap)\n",
    "# cm_avg berisi nilai confusion matrix hasil rata-rata 5-fold CV\n",
    "# aspect=\"auto\" agar skala sumbu menyesuaikan ukuran matriks\n",
    "plt.imshow(cm_avg, aspect=\"auto\")\n",
    "\n",
    "# Menampilkan colorbar di samping gambar\n",
    "# Colorbar menunjukkan intensitas warna (besar-kecilnya nilai)\n",
    "plt.colorbar()\n",
    "\n",
    "# Judul plot\n",
    "plt.title(\"Confusion Matrix Rata-rata (5-Fold CV)\")\n",
    "# Label sumbu X (kolom) = kelas hasil prediksi model\n",
    "plt.xlabel(\"Predicted\")\n",
    "# Label sumbu Y (baris) = kelas label sebenarnya (ground truth)\n",
    "plt.ylabel(\"True\")\n",
    "# Mengatur layout agar tidak ada teks yang terpotong\n",
    "plt.tight_layout()\n",
    "# Menampilkan plot ke layar\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DtRLwhKqsvpK",
    "outputId": "667a5703-4a38-4be6-9112-b607cd88ac33"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer you are loading from './best_fold_model' with an incorrect regex pattern: https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503/discussions/84#69121093e8b480e709447d5e. This will lead to incorrect tokenization. You should set the `fix_mistral_regex=True` flag when loading this tokenizer to fix this issue.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q: Cara pinjam ruangan PPBS?\n",
      " - prosedur_peminjaman_ruangan_ppbs: 0.0291\n",
      " - info_jadwal_pkrs: 0.0240\n",
      " - prosedur_pengajuan_seminar_tugas_akhir: 0.0202\n",
      " - info_lewat_batas_waktu_pkrs: 0.0191\n",
      " - info_jadwal_pengisian_krs: 0.0187\n",
      "\n",
      "Q: Cara isi KRS?\n",
      " - prosedur_pengisian_krs: 0.0291\n",
      " - prosedur_konversi_sks_mbkm: 0.0283\n",
      " - prosedur_akses_cetak_kks: 0.0283\n",
      " - konsekuensi_keterlambatan_pengisian_krs: 0.0249\n",
      " - info_fungsi_staf_tu_program_studi: 0.0208\n",
      "\n",
      "Q: Gimana alur skripsi dari awal sampai selesai?\n",
      " - info_prosedur_pelaksanaan_skripsi_sampai_wisuda: 0.0247\n",
      " - prosedur_pengurusan_surat_keterangan_aktif: 0.0242\n",
      " - prosedur_upload_tugas_akhir_repository: 0.0210\n",
      " - prosedur_akses_format_penulisan_skripsi_magang: 0.0201\n",
      " - info_repository_tugas_akhir: 0.0173\n",
      "\n",
      "Q: Cara isi absen matkul?\n",
      " - prosedur_absensi_kuliah_pacis: 0.0298\n",
      " - prosedur_koreksi_absensi: 0.0289\n",
      " - prosedur_pengurusan_cetak_ulang_ijazah: 0.0252\n",
      " - info_jadwal_pembayaran_ukt_dan_her_registrasi: 0.0215\n",
      " - prosedur_pengajuan_legalisir_transkrip_nilai: 0.0191\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "# Import tokenizer dan model untuk inference (deploy)\n",
    "\n",
    "# Menentukan device:\n",
    "# - GPU (cuda) jika tersedia\n",
    "# - CPU jika tidak ada GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Memuat tokenizer yang disimpan dari fold terbaik\n",
    "# Tokenizer ini HARUS sama dengan tokenizer saat training\n",
    "deploy_tokenizer = AutoTokenizer.from_pretrained(BEST_DIR)\n",
    "\n",
    "# Memuat model klasifikasi intent dari folder BEST_DIR\n",
    "deploy_model = AutoModelForSequenceClassification.from_pretrained(BEST_DIR).to(device)\n",
    "\n",
    "# Mengatur model ke mode evaluasi\n",
    "# agar:\n",
    "# - dropout dimatikan\n",
    "# - hasil prediksi konsisten\n",
    "deploy_model.eval()\n",
    "\n",
    "# Membaca mapping index → nama intent\n",
    "# File ini disimpan saat training\n",
    "with open(os.path.join(BEST_DIR, \"label_names.json\"), \"r\", encoding=\"utf-8\") as f:\n",
    "    label_names = json.load(f)\n",
    "\n",
    "\n",
    "def predict_topk(text, top_k=5):\n",
    "    \"\"\"\n",
    "    Melakukan prediksi intent untuk satu input teks\n",
    "    dan mengembalikan top-k intent dengan probabilitas tertinggi\n",
    "    \"\"\"\n",
    "\n",
    "    # Tokenisasi input teks\n",
    "    # return_tensors=\"pt\" -> output berupa tensor PyTorch\n",
    "    inputs = deploy_tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        max_length=MAX_LENGTH,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    # Memindahkan input ke device yang sama dengan model (CPU/GPU)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    # Menonaktifkan perhitungan gradien (hemat memori & lebih cepat)\n",
    "    with torch.no_grad():\n",
    "        # Forward pass model\n",
    "        # logits = skor mentah untuk setiap intent\n",
    "        logits = deploy_model(**inputs).logits\n",
    "\n",
    "    # Mengubah logits menjadi probabilitas menggunakan softmax\n",
    "    # squeeze(0) menghilangkan dimensi batch -> shape jadi [num_classes]\n",
    "    probs = F.softmax(logits, dim=1).squeeze(0)\n",
    "\n",
    "    # Mengambil top-k probabilitas terbesar\n",
    "    # vals = nilai probabilitas\n",
    "    # idxs = index kelas\n",
    "    vals, idxs = torch.topk(probs, k=top_k)\n",
    "\n",
    "    # Mengembalikan hasil dalam bentuk:\n",
    "    # (nama_intent, probabilitas)\n",
    "    return [(label_names[i], float(v)) for v, i in zip(vals.tolist(), idxs.tolist())]\n",
    "\n",
    "\n",
    "# Contoh pertanyaan untuk pengujian chatbot\n",
    "tests = [\n",
    "    \"Cara pinjam ruangan PPBS?\",\n",
    "    \"Cara isi KRS?\",\n",
    "    \"Gimana alur skripsi dari awal sampai selesai?\",\n",
    "    \"Cara isi absen matkul?\"\n",
    "]\n",
    "\n",
    "# Melakukan prediksi top-5 intent untuk setiap pertanyaan\n",
    "for t in tests:\n",
    "    print(\"\\nQ:\", t)\n",
    "    for tag, p in predict_topk(t, top_k=5):\n",
    "        print(f\" - {tag}: {p:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "BhHVVsLZWUUu",
    "outputId": "2d08fd4c-dca6-406c-f013-eee0ef2c49fa"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_a0fb4234-fc75-41a5-b9e8-54a20ba36d23\", \"best_fold_model.zip\", 344107898)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.make_archive(\n",
    "    \"best_fold_model\",  # nama file zip\n",
    "    \"zip\",              # format zip\n",
    "    BEST_DIR             # folder yang mau di-zip\n",
    ")\n",
    "from google.colab import files\n",
    "files.download(\"best_fold_model.zip\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
